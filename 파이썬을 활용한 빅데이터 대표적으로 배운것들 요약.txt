파이썬을 활용한 빅데이터 수집 배운것들 대표적으로만 간략하게 쓴것

5/4 ( 1일차 )

★리스트 컴프리헨션이란? 
리스트 안에 표현식(계산식)과 for문, if문을 한줄에 넣어서 새로운 리스트를 만드는 것
a = [x for x in range(10)]
print(a)



★Numpy : 파이썬을 통해 분석을 하는경우 사용하는 기초 라이브러리
	1.	행렬 / 배열의 처리 및 연산
	2.	과학 계산을 위한 라이브러리	
	3. 	난수 생성


<사용방법>
import numpy as np

기본적인 배열 예시 
b = np.array(a)             # a의 리스트 행렬을 np 넘파이 형태의 다차원 배열로 만들겠다
print(b)      


-------------------------------------------데이터 수집 -----------------------------------------------------------------------
★웹 크롤링
웹 크롤러(Web Crawler)는 웹문서, 이미지 등을 주기적으로 수집하여 자동으로 데이터베이스화하는 프로그램

웹 크롤러가 하는 작업을 웹 크롤링(Web Crawling)이라고 부릅니다.

보통 웹 크롤러를 사용하여 웹문서의 복사본을 생성합니다. 검색 엔진은 이렇게 생성된 데이터를 인덱싱하여 빠른 검색을 할 수 있도록 합니다.

‘크롤러’는 데이터 추출의 의미보다 웹 사이트를 탐색하고, 인덱싱 하는 것에 더 중점적인 의미를 갖고 있는 것 처럼 보입니다.

<사용방법>
import urllib.request


★웹 스크래핑 
웹 페이지 중에 일부 부분을 추출하는 작업
from bs4 import BeautifulSoup

BeautifulSoup: 웹 페이지의 정보를 쉽게 스크랩할 수 있도록 기능을 제공하는 라이브러리입니다.

Requests: HTTP 요청을 보낼 수 있도록 기능을 제공하는 라이브러리 입니다.

parser 는 웹 상의 자연어, 컴퓨터 언어 등의 일련의 문자열들을 분석하는 프로세스입니다.


★파일타입:
XML    - html 처럼 <>?</> 형식
	
	<header>
	<resultCode>00</resultCode>
	<resultMsg>NORMAL SERVICE</resultMsg>
	</header>
	
	=>key는 header value는 header안에있는것들이지만 진짜 value는 00, NORMAL SERVICE


JSON   - key : value



==================================================================================
5/9 (2일차)


★Numpy : 파이썬을 통해 분석을 하는경우 사용하는 기초 라이브러리
	1.	행렬 / 배열의 처리 및 연산
	2.	과학 계산을 위한 라이브러리	
	3. 	난수 생성


dtype = data type으 의미

데이터값이 하나라도 실수가 있으면 실수로 타입이 출력된다

astype 타입을 캐스팅하는거임

arr2 =np.sqrt(arr)        # sqrt 는 '루트' 입힌다는 거임

arr = np.random.randint(0,100,5)  #랜덤 정수 0~ 100까지 5개     (시작,끝값-1 , 개수)

★정규분포 : 
heights = np.random.normal(172.5,scale=5,size=1000) #표준평균분포 (정규분포) => np.random.normal()
print(sum(heights)/len(heights)) 

import math
SQRT_TWO_PI = math.sqrt(2*math.pi) #루트 2파이
def normal_pdf(x,mu=0,sigma=1):  #정규분포(mu: 평균, sigma:표준편차)
  pre = 1/(sigma*SQRT_TWO_PI)
  post = math.exp(-((x-mu)**2)/(2*(sigma**2)))
  return pre*post

xs = [x/10.0 for x  in range(-50,50)] # -5에서 5까지 step 0.1로 리스트 구성
ys1= [normal_pdf(x) for x in xs] # 표준 정규 분포
ys2= [normal_pdf(x,mu=1) for x in xs] # 정규 분포 , 평균 :1 , 표준편차 : 1
ys3= [normal_pdf(x,sigma=2) for x in xs] # 정규분포 , 평균 :0 , 표준편차 : 2 
ys4= [normal_pdf(x,sigma=0.5) for x in xs] # 정규분포 , 평균 : 0 , 표준편차 :0.5

plt.plot(xs,ys1,'-',label='mu=0, sigma=1')
plt.plot(xs,ys2,'--',label='mu=1, sigma=1')
plt.plot(xs,ys3,':',label='mu=0, sigma=2')
plt.plot(xs,ys4,'-',label='mu=0, sigma=0.5')
plt.legend()
plt.show()    



★
from collections import Counter

sample_data = [1,2,3,2,1,2,1,2,3,4,2,2,1,2,3,2]
h = Counter(sample_data)       #안에 숫자 갯수 세주는 함수 Counter
        



★
데이터시각화 matplotlib.pyplot 맛만보기

import matplotlib.pyplot as plt      # 그래프 호출
plt.plot(heights,'.')       #height 그래프를 '.' 으로 표시해달라고 요청
plt.show()            #그래프 보여달라 메소드요청



===============================================================================
5/10(3일차)

import pandas as pd 

★★★
Pandas(판다스)
고수준의 자료구조와 파이썬에서 빠르고 쉽게 사용할 수 있는
데이터 분석도구를 포함하고 있다.


★
Column을 표현하기위한 Series

★
DataFrame : 표같은 스프레드시트 형식의 자료구조





선형회귀






















